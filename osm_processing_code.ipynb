{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "import time\n",
    "\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import schema\n",
    "\n",
    "SCHEMA = schema.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In and out files\n",
    "#OSM_FILE = 'swlondon_sample.osm' \n",
    "OSM_FILE = 'swlondon.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## STREET NAME CLEANING CODE & FUNCTIONS  \n",
    "\n",
    "expected = ['Approach','Avenue','Bank','Boulevard','Bridge','Broadway','Buildings','Causeway','Centre',\n",
    "            'Chase','Close','Common','Copse','Corner','Cottages','Court','Crescent','Croft',\n",
    "           'Crossway','Cutting','Deep','Drive','East', 'Embankment','Gardens','Green','Grove','Heath','Hill',\n",
    "            'Heights','Lane','Mall','Meadows','Mews','North','Path','Parade','Park','Place','Quadrant','Quay',\n",
    "            'Rise','Road','Row', 'South','Square','Street','Terrace','Vale','Villas','Walk','Way','West']\n",
    "\n",
    "\n",
    "name_mapping = { 'St': 'Street',\n",
    "            'St.': 'Street',\n",
    "            'Strreet': 'Street',\n",
    "            'street': 'Street',\n",
    "            'Rd.':'Road',\n",
    "            'Rd' : 'Road',\n",
    "            'ROAD':'Road',\n",
    "            'road':'Road',\n",
    "            'Ave':'Avenue',\n",
    "            'Avenuen':'Avenue',\n",
    "            'lane': 'Lane',\n",
    "            'park':'Park'           \n",
    "            } # etc. to be updated\n",
    "\n",
    "\n",
    "problem_street_names = ['11', '218','24', 'Rectory Grove Hampton TW12 1EG','Fulham Road, Chelsea',\n",
    "                        'Sheffield Rd, Heathrow Airport (LHR)','Beacon Rd (Entrance Sanctuary Rd)',\n",
    "                        'Wimbledon']\n",
    "    \n",
    "change_list_mapping = { 'Rectory Grove Hampton TW12 1EG': 'Rectory Grove',\n",
    "                        'Sheffield Rd, Heathrow Airport (LHR)': 'Sheffield Road',\n",
    "                        'Beacon Rd (Entrance Sanctuary Rd)': 'Beacon Road',\n",
    "                        'Fulham Road, Chelsea': 'Fulham Road',\n",
    "                        'Wimbledon' : 'Wimbledon Hill Road'}\n",
    "\n",
    "drop_list = ['11', '218','24']\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def update_name(name):\n",
    "    #print (name.split()[-1])\n",
    "    if name in drop_list:\n",
    "        return 'DROP TAG'\n",
    "    if name in change_list_mapping:\n",
    "        name = change_list_mapping[name]\n",
    "        return name\n",
    "    name_list = name.split()\n",
    "    try:\n",
    "        name_list[-1] = name_mapping[name_list[-1]]\n",
    "        name_list[0] = name_list[0].title()\n",
    "        return ' '.join(name_list)\n",
    "    except:\n",
    "        return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for cleaning problem tag types\n",
    "\n",
    "problem_tag_list = ['bus:lanes:backward', 'bus:lanes:forward','psv:lanes',\n",
    "                    'motorcycle:lanes:forward','psv:lanes:backward',\n",
    "                    'psv:lanes:forward']\n",
    " \n",
    "tag_type_mapping = {'bus:lanes:backward':'lanes:bus:backward',\n",
    "                    'bus:lanes:forward' : 'lanes:bus:forward',\n",
    "                    'motorcycle:lanes:forward' : 'lanes:motorcycle:forward',\n",
    "                    'psv:lanes': 'lanes:psv',\n",
    "                    'psv:lanes:backward': 'lanes:psv:backward',\n",
    "                    'psv:lanes:forward' : 'lanes:psv:forward'\n",
    "                    }\n",
    "\n",
    "\n",
    "def is_problem_type(elem):\n",
    "    return (elem.attrib['k'] in problem_tag_list)\n",
    "\n",
    "\n",
    "def update_tag_type(tag_type):\n",
    "    if tag_type in tag_type_mapping:\n",
    "        tag_type = tag_type_mapping[tag_type]\n",
    "        return tag_type\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for cleaning postcode problem\n",
    "\n",
    "def is_postcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "\n",
    "\n",
    "def clean_postcode(code):\n",
    "    if ';' in code:\n",
    "        print 'CLEANING A POSTCODE:', code\n",
    "        code = code.split(';')[0]\n",
    "        print 'NEW POSTCODE:', code\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CLEAN STREET NAME:', 'WALTON ROAD', '=>', 'Walton Road')\n",
      "('CLEAN STREET NAME:', 'Rectory Grove Hampton TW12 1EG', '=>', 'Rectory Grove')\n",
      "('CLEAN STREET NAME:', 'Cobham Rd', '=>', 'Cobham Road')\n",
      "('CLEAN STREET NAME:', 'Langdon park', '=>', 'Langdon Park')\n",
      "('CLEAN STREET NAME:', \"St John's Rd\", '=>', \"St John's Road\")\n",
      "('CLEAN STREET NAME:', 'sydney street', '=>', 'Sydney Street')\n",
      "('CLEAN STREET NAME:', 'Town lane', '=>', 'Town Lane')\n",
      "('CLEAN STREET NAME:', 'Eden St', '=>', 'Eden Street')\n",
      "('CLEAN STREET NAME:', '218', '=>', 'DROP TAG')\n",
      "DROPPING TAG FROM: 3936254366\n",
      "('CLEAN STREET NAME:', 'Spur Rd', '=>', 'Spur Road')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Baywillow Ave', '=>', 'Baywillow Avenue')\n",
      "('CLEAN STREET NAME:', 'Ewell Rd', '=>', 'Ewell Road')\n",
      "('CLEAN STREET NAME:', 'Ebury Strreet', '=>', 'Ebury Street')\n",
      "('CLEAN STREET NAME:', 'Hillbrook Rd', '=>', 'Hillbrook Road')\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "('CLEAN STREET NAME:', 'Sheffield Rd, Heathrow Airport (LHR)', '=>', 'Sheffield Road')\n",
      "('CLEAN STREET NAME:', 'Kingston Avenuen', '=>', 'Kingston Avenue')\n",
      "('CLEAN STREET NAME:', '11', '=>', 'DROP TAG')\n",
      "DROPPING TAG FROM: 30427523\n",
      "('CLEAN STREET NAME:', 'Warwick Rd', '=>', 'Warwick Road')\n",
      "('CLEAN STREET NAME:', 'Warwick Rd', '=>', 'Warwick Road')\n",
      "('CLEAN STREET NAME:', 'Warwick Rd', '=>', 'Warwick Road')\n",
      "('CLEAN STREET NAME:', 'Warwick Rd', '=>', 'Warwick Road')\n",
      "('CLEAN STREET NAME:', 'Warwick Rd', '=>', 'Warwick Road')\n",
      "('CLEAN STREET NAME:', 'Warwick Rd', '=>', 'Warwick Road')\n",
      "('CLEAN STREET NAME:', 'Fulham Road, Chelsea', '=>', 'Fulham Road')\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "('CLEAN STREET NAME:', 'Quintin Ave', '=>', 'Quintin Avenue')\n",
      "('CLEAN STREET NAME:', 'Quintin Ave', '=>', 'Quintin Avenue')\n",
      "FOUND A PROBLEM TAG TYPE: bus:lanes:forward\n",
      "CHANGED TO: lanes:bus:forward\n",
      "FOUND A PROBLEM TAG TYPE: bus:lanes:forward\n",
      "CHANGED TO: lanes:bus:forward\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes:backward\n",
      "CHANGED TO: lanes:psv:backward\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes\n",
      "CHANGED TO: lanes:psv\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes:forward\n",
      "CHANGED TO: lanes:psv:forward\n",
      "('CLEAN STREET NAME:', 'Beacon Rd (Entrance Sanctuary Rd)', '=>', 'Beacon Road')\n",
      "('CLEAN STREET NAME:', 'Kings road', '=>', 'Kings Road')\n",
      "('CLEAN STREET NAME:', '24', '=>', 'DROP TAG')\n",
      "DROPPING TAG FROM: 244995917\n",
      "FOUND A PROBLEM TAG TYPE: bus:lanes:backward\n",
      "CHANGED TO: lanes:bus:backward\n",
      "('CLEAN STREET NAME:', 'Kew Bridge Rd', '=>', 'Kew Bridge Road')\n",
      "FOUND A PROBLEM TAG TYPE: motorcycle:lanes:forward\n",
      "CHANGED TO: lanes:motorcycle:forward\n",
      "FOUND A PROBLEM TAG TYPE: psv:lanes:forward\n",
      "CHANGED TO: lanes:psv:forward\n",
      "FOUND A PROBLEM TAG TYPE: bus:lanes:forward\n",
      "CHANGED TO: lanes:bus:forward\n",
      "CLEANING A POSTCODE: SW19 4LL;SW19 4LW\n",
      "NEW POSTCODE: SW19 4LL\n",
      "('CLEAN STREET NAME:', 'Wimbledon', '=>', 'Wimbledon Hill Road')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "\n",
    "# re expressions as used in code\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "NAPTAN = re.compile(r'^(naptan:|Naptan:)[a-zA-Z]*$')\n",
    "\n",
    "#SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "# A function to shape the tags and add to the relevant dict objects.\n",
    "# Used for both nodes and way tags - as treatment is the same.\n",
    "# Takes list of desired tag fields (from NODE_TAGS_FIELDS)\n",
    "# For id (an attrb from parent node or way and NOT in tag), parent node / way id is returned\n",
    "# for 'key' checks if: \n",
    "#                      a PROBLEMCHARS match, and ignores / drops\n",
    "#                      a LOWER_COLON or NAPTAN match and splits, extracts / sets type (text before :) \n",
    "#                                        and returns rest as key\n",
    "#                       (NOTE - type is 'regular' if no other found)\n",
    "# added .lower() on tag_dict type & field setting to remove block capital inconsistencies etc.\n",
    "\n",
    "def shape_tags(element, id_number, tag_attr_fields = NODE_TAGS_FIELDS,\n",
    "                   problem_chars=PROBLEMCHARS, lower_colon=LOWER_COLON,\n",
    "                   naptan=NAPTAN, default_tag_type='regular'):\n",
    "    tag_dict={}\n",
    "    for field in tag_attr_fields:\n",
    "        # manage id number (from parent node / way)\n",
    "        if field == 'id':\n",
    "            tag_dict[field]= id_number\n",
    "            \n",
    "        # process 'keys'   \n",
    "        elif field == 'key':\n",
    "            tag_dict['type'] = default_tag_type\n",
    "            if problem_chars.search(element.attrib['k']):\n",
    "                print 'IGNORING A TAG - PROBLEM CHARS', element.attrib['k']\n",
    "                tag_dict={}\n",
    "                return None\n",
    "            elif lower_colon.search(element.attrib['k']) or naptan.search(element.attrib['k']):\n",
    "                k = element.attrib['k']\n",
    "                if is_problem_type(element):\n",
    "                    print 'FOUND A PROBLEM TAG TYPE:', k\n",
    "                    k = update_tag_type(k)\n",
    "                    print 'CHANGED TO:', k\n",
    "                \n",
    "                split_k =  k.lower().split(':')\n",
    "                tag_dict['type'] = split_k[0]\n",
    "                tag_dict[field] = ':'.join(split_k[1:])\n",
    "            else:\n",
    "                tag_dict[field]= element.attrib['k'].lower()\n",
    "        \n",
    "        # process values (and call on cleaning)\n",
    "        elif field == 'value':\n",
    "            if is_street_name(element):\n",
    "                original_name = element.attrib['v']\n",
    "                cleaned_name = update_name(original_name)\n",
    "                if cleaned_name != original_name:\n",
    "                    print ('CLEAN STREET NAME:', original_name, \"=>\", cleaned_name)\n",
    "                    if cleaned_name == 'DROP TAG':\n",
    "                        print 'DROPPING TAG FROM:', id_number\n",
    "                        tag_dict={}\n",
    "                        return None\n",
    "                    tag_dict[field] = cleaned_name\n",
    "                    continue\n",
    "                else:\n",
    "                    tag_dict[field] = original_name\n",
    "                    continue\n",
    "            \n",
    "            elif is_postcode(element):\n",
    "                tag_dict[field] = clean_postcode(element.attrib['v'])\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                tag_dict[field]= element.attrib['v']\n",
    "      \n",
    "    return tag_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def shape_way_nodes(element, id_number, position, way_node_fields=WAY_NODES_FIELDS):\n",
    "    way_node_dict = {}\n",
    "    for field in way_node_fields:\n",
    "        if field == 'id':\n",
    "            way_node_dict[field]= id_number\n",
    "        elif field == 'position':\n",
    "            way_node_dict[field]= position\n",
    "        elif field == 'node_id':\n",
    "            way_node_dict[field]= element.attrib['ref']\n",
    "    return way_node_dict\n",
    "            \n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for field in node_attr_fields:\n",
    "            node_attribs[field]= element.attrib[field]\n",
    "            id_number = element.attrib['id']\n",
    "        for tag in element.iter('tag'):\n",
    "            tag_dict = shape_tags(tag, id_number)\n",
    "            if tag_dict is not None:\n",
    "                tags.append(tag_dict)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "        \n",
    "    elif element.tag == 'way':\n",
    "        for field in way_attr_fields:\n",
    "            way_attribs[field]= element.attrib[field]\n",
    "            id_number = element.attrib['id']        \n",
    "        for tag in element.iter('tag'):\n",
    "            tag_dict = shape_tags(tag, id_number)\n",
    "            if tag_dict is not None:\n",
    "                tags.append(tag_dict)\n",
    "        position = 0\n",
    "        for way_node in element.iter('nd'):\n",
    "            way_nodes.append(shape_way_nodes(way_node, id_number, position))\n",
    "            position += 1     \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_FILE, validate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CODE to create database, drop tables and create schema as required for osm data\n",
    "\n",
    "conn = sqlite3.connect('swlondon.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Drop any existing tables\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "\n",
    "\n",
    "# Create tables:\n",
    "cur.execute('''\n",
    "CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT \n",
    "    );\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\n",
    "    );\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    "    );\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "def parse_csv(datafile):\n",
    "    data=[]\n",
    "    n=0\n",
    "    with open(datafile, 'r') as sd:\n",
    "        r = csv.DictReader(sd)\n",
    "        for line in r:\n",
    "            data.append(line)\n",
    "        return data\n",
    "    \n",
    "nodes_data = parse_csv(NODES_PATH)\n",
    "nodes_tags_data = parse_csv(NODE_TAGS_PATH)\n",
    "ways_data = parse_csv(WAYS_PATH)\n",
    "ways_nodes_data = parse_csv(WAY_NODES_PATH)\n",
    "ways_tags_data = parse_csv(WAY_TAGS_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "#NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "#NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "#WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "#WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "#WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "def write_node_line (data):    \n",
    "    cur.execute(\n",
    "        '''\n",
    "    INSERT into nodes (id, lat, lon, user, uid, version, changeset, timestamp) \n",
    "    VALUES (?,?,?,?,?,?,?,?)\n",
    "        ''',\n",
    "    (data['id'].decode('utf-8'), data['lat'].decode('utf-8'), data['lon'].decode('utf-8'),\n",
    "     data['user'].decode('utf-8'), data['uid'].decode('utf-8'), \n",
    "     data['version'].decode('utf-8'), data['changeset'].decode('utf-8'),\n",
    "     data['timestamp'].decode('utf-8'))\n",
    "    )\n",
    "\n",
    "def write_node_tags_line (data):    \n",
    "    cur.execute(\n",
    "        '''\n",
    "    INSERT into nodes_tags (id, key, value, type) \n",
    "    VALUES (?,?,?,?)\n",
    "        ''',\n",
    "    (data['id'].decode('utf-8'), data['key'].decode('utf-8'),\n",
    "     data['value'].decode('utf-8'), data['type'].decode('utf-8'))\n",
    "    )\n",
    "    \n",
    "\n",
    "def write_ways_line (data):    \n",
    "    cur.execute(\n",
    "        '''\n",
    "    INSERT into ways (id, user, uid, version, changeset, timestamp) \n",
    "    VALUES (?,?,?,?,?,?)\n",
    "        ''',\n",
    "    (data['id'].decode('utf-8'), data['user'].decode('utf-8'), data['uid'].decode('utf-8'),\n",
    "     data['version'].decode('utf-8'),\n",
    "      data['changeset'].decode('utf-8'), data['timestamp'].decode('utf-8'))\n",
    "    ) \n",
    "\n",
    "    \n",
    "def write_ways_tags_line (data):    \n",
    "    cur.execute(\n",
    "        '''\n",
    "    INSERT into ways_tags (id, key, value, type) \n",
    "    VALUES (?,?,?,?)\n",
    "        ''',\n",
    "    (data['id'].decode('utf-8'), data['key'].decode('utf-8'),\n",
    "     data['value'].decode('utf-8'), data['type'].decode('utf-8'))\n",
    "    )   \n",
    "    \n",
    "def write_ways_nodes_line (data):    \n",
    "    cur.execute(\n",
    "        '''\n",
    "    INSERT into ways_nodes (id, node_id, position) \n",
    "    VALUES (?,?,?)\n",
    "        ''',\n",
    "    (data['id'].decode('utf-8'), data['node_id'].decode('utf-8'), \n",
    "     data['position'].decode('utf-8'))\n",
    "    ) \n",
    "\n",
    "\n",
    "DATA_DICTS = [nodes_data, nodes_tags_data, ways_data, ways_nodes_data, ways_tags_data]\n",
    "READ_FNS = [write_node_line, write_node_tags_line, write_ways_line, write_ways_nodes_line, write_ways_tags_line]\n",
    "    \n",
    "    \n",
    "for data, function in zip(DATA_DICTS,READ_FNS):\n",
    "    n=0\n",
    "    for line in data:\n",
    "        n+=1\n",
    "        if n%10000==0:\n",
    "            conn.commit()\n",
    "        function(line)\n",
    "\n",
    "            \n",
    "conn.commit()\n",
    "print 'DONE!'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
